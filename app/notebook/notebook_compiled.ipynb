{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc2252c-d896-4671-9c42-686fd988ebc6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87ed12-1e64-483b-a532-410c7fbbd909",
   "metadata": {},
   "source": [
    "Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d2493e-7fa7-447e-8f63-4b3b98944a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c26a9e-5d82-425b-88fb-dc99d94cb478",
   "metadata": {},
   "source": [
    "# Load & Split Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132555e-53ff-49e1-8607-744a576adc24",
   "metadata": {},
   "source": [
    "Load and split dataset:\n",
    "<li>- Make each processing step as a function</li>\n",
    "<li>- Make main funtion</li>\n",
    "<li>- Create parameters to load & split the data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90cab445-840b-47db-b41f-bc488ba3ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path,\n",
    "              set_index = None):\n",
    "    '''\n",
    "    Read data from data folder in csv format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "          path to data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv(path, index_col = set_index)\n",
    "\n",
    "    return data\n",
    "\n",
    "def split_input_output(dataset,\n",
    "                       target_column):\n",
    "    '''\n",
    "    Function to split input and output data\n",
    "    '''\n",
    "    output_df = dataset[target_column]\n",
    "    input_df = dataset.drop([target_column],\n",
    "                            axis = 1)\n",
    "\n",
    "    return output_df, input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f442651e-7b9f-4624-9c7a-c3faa65424df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_di(input_data):\n",
    "    '''\n",
    "    Function to load only IVF data\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data = data[data['Type of treatment - IVF or DI'] != 'DI']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def select_feats(input_data, selected_cols):\n",
    "    '''\n",
    "    Function to select only the necessary feature\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data = data[selected_cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main_data(input_data, selected_cols):\n",
    "    '''\n",
    "    Main function to load data\n",
    "    '''\n",
    "    data = exclude_di(input_data)\n",
    "    data = select_feats(data, selected_cols)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def impute_target(input_data, target_col):\n",
    "    '''\n",
    "    Function to impute target variable\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data[target_col] = data[target_col].fillna(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f2d6f5-1474-4df2-99d0-3b133c12f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x, y, TEST_SIZE):\n",
    "    # Do not forget to stratify if classification\n",
    "    x_train, x_test,\\\n",
    "        y_train, y_test = train_test_split(x,\n",
    "                                           y,\n",
    "                                           test_size=TEST_SIZE,\n",
    "                                           random_state=123,\n",
    "                                           stratify=y)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def split_data(data_input, data_ouput, TEST_SIZE=0.2):\n",
    "\n",
    "    x_train, x_test, \\\n",
    "        y_train, y_test = split_train_test(\n",
    "            data_input,\n",
    "            data_ouput,\n",
    "            TEST_SIZE)\n",
    "\n",
    "    x_train, x_valid, \\\n",
    "        y_train, y_valid = split_train_test(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            TEST_SIZE)\n",
    "\n",
    "    return x_train, y_train, \\\n",
    "        x_valid, y_valid, \\\n",
    "        x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d64b8b5-0ffd-4377-9f74-75c79e439c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'file_loc1': '../data/ar-2010-2014-csv.csv',\n",
    "          'file_loc2': '../data/ar-2015-2016-csv.csv',\n",
    "          'target_column': 'Live Birth Occurrence',\n",
    "         'feats': ['Patient Age at Treatment',\n",
    "        'Total Number of Previous IVF cycles',\n",
    "        'Total number of IVF pregnancies',\n",
    "        'Total number of live births - conceived through IVF',\n",
    "        'Type of Infertility - Female Primary',\n",
    "        'Type of Infertility - Female Secondary',\n",
    "        'Type of Infertility - Male Primary',\n",
    "        'Type of Infertility - Male Secondary',\n",
    "        'Type of Infertility -Couple Primary',\n",
    "        'Type of Infertility -Couple Secondary',\n",
    "        'Cause  of Infertility - Tubal disease',\n",
    "        'Cause of Infertility - Ovulatory Disorder',\n",
    "        'Cause of Infertility - Male Factor',\n",
    "        'Cause of Infertility - Patient Unexplained',\n",
    "        'Cause of Infertility - Endometriosis',\n",
    "        'Cause of Infertility - Cervical factors',\n",
    "        'Cause of Infertility - Female Factors',\n",
    "        'Cause of Infertility - Partner Sperm Concentration',\n",
    "        'Cause of Infertility -  Partner Sperm Morphology',\n",
    "        'Causes of Infertility - Partner Sperm Motility',\n",
    "        'Cause of Infertility -  Partner Sperm Immunological factors',\n",
    "        'Stimulation used',\n",
    "        'Egg Source',\n",
    "        'Sperm From', \n",
    "        'Fresh Cycle', \n",
    "        'Frozen Cycle', \n",
    "        'Eggs Thawed',\n",
    "        'Fresh Eggs Collected', \n",
    "        'Eggs Mixed With Partner Sperm',\n",
    "        'Embryos Transfered',\n",
    "        'Live Birth Occurrence'],\n",
    "        'test_size': 0.2,\n",
    "        'out_path': '../output/'\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63748036-0b1d-44b7-85f4-d79fd11478f7",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2085c-cb75-45e4-9ffa-7188b3e4e60e",
   "metadata": {},
   "source": [
    "Main function for loading and splitting dataset:\n",
    "<li>- Input & output data split</li>\n",
    "<li>- Train-Valid-Test split with stratification</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1b68d3-7036-4570-af7d-f43900a8a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_load(params):\n",
    "    df1 = read_data(params['file_loc1'])\n",
    "    df2 = read_data(params['file_loc2'])\n",
    "    data = pd.concat([df1, df2])\n",
    "    data = main_data(data,params['feats'])\n",
    "    data = impute_target(data,params['target_column'])\n",
    "\n",
    "    output_df, input_df = split_input_output(data,\n",
    "                                         params['target_column'])\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = split_data(input_df,\n",
    "                                                                output_df,\n",
    "                                                                params['test_size'])\n",
    "    \n",
    "    joblib.dump(X_train, params[\"out_path\"]+\"x_train.pkl\")\n",
    "    joblib.dump(y_train, params[\"out_path\"]+\"y_train.pkl\")\n",
    "    joblib.dump(X_valid, params[\"out_path\"]+\"x_valid.pkl\")\n",
    "    joblib.dump(y_valid, params[\"out_path\"]+\"y_valid.pkl\")\n",
    "    joblib.dump(X_test, params[\"out_path\"]+\"x_test.pkl\")\n",
    "    joblib.dump(y_test, params[\"out_path\"]+\"y_test.pkl\")\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5222cb5d-0368-46d5-b3fb-eb4f4d1d4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = main_load(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8b3cef-9bd9-4d09-a4a7-e2476dd07e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92672,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8efbca2-26e2-48dd-b080-eaaa3dd51283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.751784\n",
      "1.0    0.248216\n",
      "Name: Live Birth Occurrence, dtype: float64\n",
      "--------------\n",
      "0.0    0.751787\n",
      "1.0    0.248213\n",
      "Name: Live Birth Occurrence, dtype: float64\n",
      "--------------\n",
      "0.0    0.751791\n",
      "1.0    0.248209\n",
      "Name: Live Birth Occurrence, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check if stratify is correct\n",
    "print(y_train.value_counts(normalize = True))\n",
    "print('--------------')\n",
    "print(y_valid.value_counts(normalize = True))\n",
    "print('--------------')\n",
    "print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196c860-96b3-4ce3-9241-869d115d3fe3",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21588494-9acf-4ef0-8f21-2f776bdf48de",
   "metadata": {},
   "source": [
    "<b>Data preprocessing:</b>\n",
    "\n",
    "<li>- Make each processing step as a function</li>\n",
    "<li>- Make main function</li>\n",
    "<li>- Create parameters for preprocessing</li>\n",
    "<li></li>\n",
    "<b>Feature engineering:</b>\n",
    "\n",
    "<li>- Generate dummy variable</li>\n",
    "<li>- Normalize the data using zscore</li>\n",
    "<li>- Undersampling for training data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce3fa6d-7718-4f7b-b9b7-96f283f76e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(input_data, do=True):\n",
    "    '''\n",
    "    Function to convert string to numerical data\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    \n",
    "    # replace '> 50' with 51\n",
    "    data['Fresh Eggs Collected'] = data['Fresh Eggs Collected'].replace(['> 50'],[51])\n",
    "    data['Eggs Mixed With Partner Sperm'] = data['Eggs Mixed With Partner Sperm'].replace(['> 50'],[51])\n",
    "    \n",
    "    # replace '>=5' with 6\n",
    "    data['Total Number of Previous IVF cycles'] = data['Total Number of Previous IVF cycles'].replace(['>=5'],[6])\n",
    "    data['Total number of IVF pregnancies'] = data['Total number of IVF pregnancies'].replace(['>=5'],[6])\n",
    "    \n",
    "    # convert to numerical data\n",
    "    data['Fresh Eggs Collected'] = pd.to_numeric(data['Fresh Eggs Collected'])\n",
    "    data['Eggs Mixed With Partner Sperm'] = pd.to_numeric(data['Eggs Mixed With Partner Sperm'])\n",
    "    data['Total Number of Previous IVF cycles'] = pd.to_numeric(data['Total Number of Previous IVF cycles'])\n",
    "    data['Total number of IVF pregnancies'] = pd.to_numeric(data['Total number of IVF pregnancies'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def replace_age(input_data, cats, do=True):\n",
    "    '''\n",
    "    Function to categorize age input\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data.drop(data[data['Patient Age at Treatment'] == '999'].index, inplace = True)\n",
    "    data['Patient Age at Treatment'] = data['Patient Age at Treatment'].replace(cats)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_dummies(input_data, col, do=True):\n",
    "    '''\n",
    "    Function to generate dummy variable\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    if 'Sperm From' in input_data.columns:\n",
    "        data = pd.get_dummies(data, columns=col, prefix=col)\n",
    "    \n",
    "    else:\n",
    "        input_data\n",
    "    \n",
    "    return data\n",
    "\n",
    "def replace_eggsrc(input_data, do=True):\n",
    "    '''\n",
    "    Function to categorize egg source input\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data['Egg Source'] = data['Egg Source'].replace(['Patient','Donor'],[0,1])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def remove_cols(input_data, cols, do=True):\n",
    "    '''\n",
    "    Function to remove unecessary columns\n",
    "    '''\n",
    "    data = input_data.copy()\n",
    "    data = data.drop(columns=cols)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def undersampling(x_train, y_train):\n",
    "    '''\n",
    "    Function to undersampling train data\n",
    "    '''\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    X_train, y_train = undersample.fit_resample(x_train, y_train)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f536edeb-0c75-4cb0-b392-9550748b6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all dict & lists needed\n",
    "params_preprocessing = {'age_replace': {'18 - 34':0, '35-37':1, '38-39':2, '40-42':3, '43-44':4, '45-50':5},\n",
    "                        'to_dummy': ['Sperm From'],\n",
    "                        'to_remove': ['Cause of Infertility - Female Factors',\n",
    "                                      'Cause of Infertility -  Partner Sperm Immunological factors',\n",
    "                                      'Type of Infertility -Couple Primary', \n",
    "                                      'Type of Infertility - Male Primary', \n",
    "                                      'Frozen Cycle', 'Fresh Cycle', \n",
    "                                      'Sperm From_Partner', \n",
    "                                      'Total number of live births - conceived through IVF', \n",
    "                                      'Eggs Mixed With Partner Sperm'],\n",
    "                       'to_numeric': True,\n",
    "                        'replace_age': True,\n",
    "                        'get_dummies': True,\n",
    "                        'replace_eggsrc': True,\n",
    "                        'remove_cols': True,\n",
    "                        'undersampling': True,\n",
    "                       'out_path': '../output/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51caabd-3fa5-491a-afe7-eab4fa740c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_data,params):\n",
    "    \"\"\"\n",
    "    A function to execute the preprocessing steps.\n",
    "    \n",
    "    Args:\n",
    "    - df_in(DataFrame): Input dataframe\n",
    "    - params(dict): preprocessing parameters\n",
    "    \n",
    "    Return:\n",
    "    - df(DataFrame): preprocessed data\n",
    "    \"\"\"\n",
    "    data = input_data.copy()\n",
    "    data = to_numeric(data, params['to_numeric'])\n",
    "    data = replace_age(data, params['age_replace'], params['replace_age'])\n",
    "    data = get_dummies(data, params['to_dummy'], params['get_dummies'])\n",
    "    data = replace_eggsrc(data, params['replace_eggsrc'])\n",
    "    data = remove_cols(data, params['to_remove'], params['remove_cols'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00adb7e-2f80-4b60-bb5f-bdd15bc898b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_eng(x_train, y_train, x_valid, y_valid, x_test, y_test, params):\n",
    "    \n",
    "    # concat data\n",
    "    df_train = pd.concat([x_train, pd.DataFrame(y_train)], axis = 1)\n",
    "    df_valid = pd.concat([x_valid, pd.DataFrame(y_valid)], axis = 1)\n",
    "    df_test = pd.concat([x_test, pd.DataFrame(y_test)], axis = 1)\n",
    "    \n",
    "    df_list = [df_train, df_valid, df_test]\n",
    "    df_preprocessed = []\n",
    "    \n",
    "    for x in df_list:\n",
    "        temp = preprocess(x, params)\n",
    "        df_preprocessed.append(temp)\n",
    "        \n",
    "    X_train_ready = df_preprocessed[0].drop(columns=['Live Birth Occurrence'], axis=1)\n",
    "    y_train_ready = df_preprocessed[0]['Live Birth Occurrence']\n",
    "    X_valid_ready = df_preprocessed[1].drop(columns=['Live Birth Occurrence'], axis=1)\n",
    "    y_valid_ready = df_preprocessed[1]['Live Birth Occurrence']\n",
    "    X_test_ready = df_preprocessed[2].drop(columns=['Live Birth Occurrence'], axis=1)\n",
    "    y_test_ready = df_preprocessed[2]['Live Birth Occurrence']\n",
    "    \n",
    "    X_train_ready = zscore(X_train_ready)\n",
    "    X_valid_ready = zscore(X_valid_ready)\n",
    "    X_test_ready = zscore(X_test_ready)\n",
    "    X_train_ready, y_train_ready = undersampling(X_train_ready, y_train_ready)\n",
    "    \n",
    "    \n",
    "    joblib.dump(X_train_ready, params[\"out_path\"]+\"X_train_ready.pkl\")\n",
    "    joblib.dump(y_train_ready, params[\"out_path\"]+\"y_train_ready.pkl\")\n",
    "    joblib.dump(X_valid_ready, params[\"out_path\"]+\"X_valid_ready.pkl\")\n",
    "    joblib.dump(y_valid_ready, params[\"out_path\"]+\"y_valid_ready.pkl\")\n",
    "    joblib.dump(X_test_ready, params[\"out_path\"]+\"X_test_ready.pkl\")\n",
    "    joblib.dump(y_test_ready, params[\"out_path\"]+\"y_test_ready.pkl\")\n",
    "    \n",
    "    return X_train_ready, y_train_ready, X_valid_ready, y_valid_ready, X_test_ready, y_test_ready "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40324b89-9cbf-4737-bb7e-0a93abd0937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ready, y_train_ready, X_valid_ready, y_valid_ready, X_test_ready, y_test_ready = main_eng(x_train, \n",
    "                                                                                                  y_train, \n",
    "                                                                                                  x_valid, \n",
    "                                                                                                  y_valid, \n",
    "                                                                                                  x_test, \n",
    "                                                                                                  y_test,\n",
    "                                                                                                 params_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cebc0954-31e0-450e-97cc-44569b71237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_ready:  (146466, 24)\n",
      "x_valid_ready:  (73057, 24)\n",
      "x_test_ready:  (91401, 24)\n"
     ]
    }
   ],
   "source": [
    "print('x_train_ready: ',X_train_ready.shape)\n",
    "print('x_valid_ready: ',X_valid_ready.shape)\n",
    "print('x_test_ready: ',X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971f5ee-f8a1-40dc-9ee1-5553dfe5ca28",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Searching for the best model and hyperparameter:\n",
    "<li>- Generate baseline model (Logistic Regression, Random Forest, Decision Tree, XGBoost)</li>\n",
    "<li>- Select the best model</li>\n",
    "<li>- Hyperparameter tuning</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37bedb68-16a1-46c2-b310-c378a891a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(X_train,y_train,X_valid,y_valid, params):\n",
    "    \n",
    "    logreg = LogisticRegression\n",
    "    rf = RandomForestClassifier\n",
    "    tree = DecisionTreeClassifier\n",
    "    XGB_ = xgb.XGBClassifier\n",
    "    \n",
    "    train_log_dict = {'model': [logreg(), rf(), tree(), XGB_()],\n",
    "                      'for_tuning': [logreg, rf, tree, XGB_], \n",
    "                      'model_name': [],\n",
    "                      'model_fit': [],\n",
    "                      'model_score': []}\n",
    "    \n",
    "    #try\n",
    "    for model in train_log_dict['model']:\n",
    "        base_model = model\n",
    "        train_log_dict['model_name'].append(base_model.__class__.__name__)\n",
    "    \n",
    "    for model in train_log_dict['model']:\n",
    "        base_model = model\n",
    "        train_log_dict['model_fit'].append(base_model.fit(X_train,y_train))\n",
    "    \n",
    "    for model in train_log_dict['model_fit']:\n",
    "        fitted_model = model\n",
    "        train_log_dict['model_score'].append((2*(roc_auc_score(y_train, fitted_model.predict_proba(X_train)[:, 1])))-1)\n",
    "        \n",
    "    best_model_index = train_log_dict['model_score'].index(max(train_log_dict['model_score']))\n",
    "    best_model = train_log_dict['model'][best_model_index]\n",
    "    best_model_ = train_log_dict['for_tuning'][best_model_index]\n",
    "                                           \n",
    "    \n",
    "    print(\"Gini Performance Evaluation\\n\")\n",
    "    print(f\"Logistic Regression Gini : {train_log_dict['model_score'][0]}\")\n",
    "    print(f\"Random Forest Gini       : {train_log_dict['model_score'][1]}\")\n",
    "    print(f\"Decision Tree Gini       : {train_log_dict['model_score'][2]}\")\n",
    "    print(f\"XGBoost Gini : {train_log_dict['model_score'][3]}\")\n",
    "    print('')\n",
    "    print(f\"Best Model : {best_model}\")\n",
    "   \n",
    "    #hyperparameter tuning\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=69)\n",
    "\n",
    "    # Define search space\n",
    "    space_tree = dict()\n",
    "\n",
    "    space_tree['max_depth'] = [2, 3, 5, 10, 20] #DT\n",
    "    space_tree['min_samples_leaf'] = [5, 10, 20, 50, 100] #DT\n",
    "    space_tree['criterion'] = [\"gini\", \"entropy\"] #DT\n",
    "\n",
    "    # Define search\n",
    "    search_tree = RandomizedSearchCV(tree(), space_tree, n_iter=30, scoring='roc_auc', n_jobs=30, cv=cv, random_state=69)\n",
    "\n",
    "    # Execute search\n",
    "    result_tree = search_tree.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = {'max_depth': result_tree.best_params_['max_depth'],\n",
    "                  'min_samples_leaf': result_tree.best_params_['min_samples_leaf'],\n",
    "                  'criterion': result_tree.best_params_['criterion']}\n",
    "\n",
    "    print('Best Score tree: %s' % ((result_tree.best_score_ * 2) - 1))\n",
    "    print('Best Hyperparameters: %s' % result_tree.best_params_)\n",
    "    \n",
    "    model_ = best_model_(max_depth= best_params['max_depth'], min_samples_leaf = best_params['min_samples_leaf'], criterion = best_params['criterion']).fit(X_train,y_train)\n",
    "    \n",
    "    def evaluate(true,predicted):\n",
    "        f1 = f1_score(true,predicted)\n",
    "        roc_auc = roc_auc_score(true,predicted)\n",
    "    \n",
    "        return f1,roc_auc\n",
    "    \n",
    "    f1, roc_auc = evaluate(y_valid, model_.predict(X_valid))\n",
    "    \n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc_auc)\n",
    "    \n",
    "    joblib.dump(model_, params['out_path']+'best_model.pkl')\n",
    "    joblib.dump(train_log_dict, params['out_path']+'train_log.pkl')\n",
    "    \n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61dd8694-b4d2-4419-9af3-053aebe78449",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_model={'out_path': \"../model/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "538b9d37-6721-4fa4-8229-57eb83c7baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Performance Evaluation\n",
      "\n",
      "Logistic Regression Gini : 0.3515170835691861\n",
      "Random Forest Gini       : 0.6278679455629468\n",
      "Decision Tree Gini       : 0.6325256821463663\n",
      "XGBoost Gini : 0.45786356768610026\n",
      "\n",
      "Best Model : DecisionTreeClassifier()\n",
      "Best Score tree: 0.41790244315588154\n",
      "Best Hyperparameters: {'min_samples_leaf': 100, 'max_depth': 10, 'criterion': 'gini'}\n",
      "F1 Score:  0.48928915210546065\n",
      "ROC AUC Score:  0.6529007299702863\n"
     ]
    }
   ],
   "source": [
    "best_model = select_model(X_train_ready,y_train_ready,X_valid_ready,y_valid_ready, param_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34de4df-44e3-436f-ac26-7ccf9d91bcbf",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082624b5-6720-49ee-ac9e-eafaac1ee1ef",
   "metadata": {},
   "source": [
    "Prediction function with dataframe as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79a3c1c-7f79-463d-8c8c-4a7f7d27bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_constructor(input):\n",
    "    df = pd.DataFrame(input, index=[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "812efe21-3697-4ceb-91bc-ce2a4c0f8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Patient Age at Treatment': '18 - 34',\n",
    "        'Total Number of Previous IVF cycles': '0',\n",
    "        'Total number of IVF pregnancies': 0,                               \n",
    "        'Total number of live births - conceived through IVF': 0,    \n",
    "        'Type of Infertility - Female Primary':0,                         \n",
    "        'Type of Infertility - Female Secondary':0,                        \n",
    "        'Type of Infertility - Male Primary':0,                          \n",
    "        'Type of Infertility - Male Secondary':0,                      \n",
    "        'Type of Infertility -Couple Primary':0,                        \n",
    "        'Type of Infertility -Couple Secondary':0,                     \n",
    "        'Cause  of Infertility - Tubal disease':1,                     \n",
    "        'Cause of Infertility - Ovulatory Disorder':0,                 \n",
    "        'Cause of Infertility - Male Factor':0,                         \n",
    "        'Cause of Infertility - Patient Unexplained':0,                  \n",
    "        'Cause of Infertility - Endometriosis':0,                        \n",
    "        'Cause of Infertility - Cervical factors':0,                     \n",
    "        'Cause of Infertility - Female Factors':0,                      \n",
    "        'Cause of Infertility - Partner Sperm Concentration':0,        \n",
    "        'Cause of Infertility -  Partner Sperm Morphology':0,          \n",
    "        'Causes of Infertility - Partner Sperm Motility':0,              \n",
    "        'Cause of Infertility -  Partner Sperm Immunological factors':0,   \n",
    "        'Stimulation used':0,                                         \n",
    "        'Egg Source': 'Patient',                                                                                           \n",
    "        'Fresh Cycle': 0,                                               \n",
    "        'Frozen Cycle':1,                                                \n",
    "        'Eggs Thawed':0,                                            \n",
    "        'Fresh Eggs Collected': '14',                                       \n",
    "        'Eggs Mixed With Partner Sperm':'14',                              \n",
    "        'Embryos Transfered':2,  \n",
    "        'Sperm From_Donor':1,                                   \n",
    "        'Sperm From_Partner & Donor':0,                          \n",
    "        'Sperm From_not assigned':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6943d1ec-204f-4604-9a1a-386698fc0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all dict & lists needed\n",
    "params_predict = {'age_replace': {'18 - 34':0, '35-37':1, '38-39':2, '40-42':3, '43-44':4, '45-50':5},\n",
    "                        'to_dummy': ['Sperm From'],\n",
    "                        'to_remove': ['Cause of Infertility - Female Factors',\n",
    "                                      'Cause of Infertility -  Partner Sperm Immunological factors',\n",
    "                                      'Type of Infertility -Couple Primary', \n",
    "                                      'Type of Infertility - Male Primary', \n",
    "                                      'Frozen Cycle', 'Fresh Cycle', \n",
    "                                      'Total number of live births - conceived through IVF', \n",
    "                                      'Eggs Mixed With Partner Sperm'],\n",
    "                       'to_numeric': True,\n",
    "                        'replace_age': True,\n",
    "                        'get_dummies': True,\n",
    "                        'replace_eggsrc': True,\n",
    "                        'remove_cols': True,\n",
    "                        'undersampling': True,\n",
    "                       'out_path': '../output/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bafeb58-4316-4196-9af5-80652859e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predict(data, model, params_preprocess):\n",
    "    df = df_constructor(data)\n",
    "    df_preprocessed = preprocess(df, params_preprocess)\n",
    "    \n",
    "    code2rel = {0: 'Not Occured', 1: 'Occured'}\n",
    "    proba = model.predict_proba(df_preprocessed)[:,1]\n",
    "    predict = 1 if proba > 0.5 else 0\n",
    "    \n",
    "    return code2rel[predict], proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33931f0f-5e32-4e56-aeba-24ad3665f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../model/best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4830016b-86eb-4b41-b662-180097731523",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict, proba = main_predict(data,model,params_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7af2b60-19c9-4367-86e3-242cba10b5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Occured'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "995efaf6-8e66-4e8a-aaa0-e22da115fe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60487805])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78db167a-001a-44a7-879d-ed117852963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5efd25-1813-440d-8cc8-f300483e93ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
